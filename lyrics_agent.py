import os
import time
import requests
from dotenv import load_dotenv
from openai import OpenAI

# Load environment variables
load_dotenv()

API_KEY = os.getenv("API_KEY")
BASE_URL = os.getenv("BASE_URL")

DEFAULT_ANALYSIS_MODEL = os.getenv("ANALYSIS_MODEL", "gemini-3-pro-preview")
DEFAULT_PROMPT_MODEL = os.getenv("PROMPT_MODEL", "gemini-3-flash-preview")
DEFAULT_IMAGE_MODEL = os.getenv("IMAGE_MODEL", "nano-banana-2-4k")
DEFAULT_TIMEOUT_SECONDS = float(os.getenv("OPENAI_TIMEOUT", "90"))
DEFAULT_IMAGE_MAX_RETRIES = int(os.getenv("IMAGE_MAX_RETRIES", "3"))
DEFAULT_IMAGE_DOWNLOAD_TIMEOUT = float(os.getenv("IMAGE_DOWNLOAD_TIMEOUT", "30"))

_client = None

def get_client():
    global _client
    if _client is None:
        if not API_KEY or not BASE_URL:
            raise RuntimeError("API_KEY or BASE_URL not found in .env file.")
        _client = OpenAI(
            api_key=API_KEY,
            base_url=BASE_URL,
            timeout=DEFAULT_TIMEOUT_SECONDS
        )
    return _client

def analyze_lyrics(raw_content, model=None):
    """
    Analyzes the lyrics/raw content using Gemini-3-Pro-Preview.
    Returns the analysis text formatted for Xiaohongshu + Metadata.
    """
    print("\nğŸµ æ­£åœ¨è¿›è¡Œæ­Œè¯æ·±åº¦èµæ (Gemini-3-Pro)...")
    client = get_client()
    
    system_prompt = """è¯·ä½ æ‰®æ¼”ä¸€ä½èµ„æ·±çš„éŸ³ä¹è¯„è®ºå®¶ã€æ–‡å­¦æ•™æˆå…¼å°çº¢ä¹¦çˆ†æ¬¾æ–‡æ¡ˆåˆ›ä½œè€…ã€‚
ä½ çš„ä»»åŠ¡æ˜¯å¯¹æä¾›çš„æ­Œè¯/æ­Œæ›²ä¿¡æ¯è¿›è¡Œæ·±åº¦çš„è‰ºæœ¯é£æ ¼åˆ†æï¼Œå¹¶è¾“å‡ºä¸€ç¯‡å¯ä»¥ç›´æ¥å‘å¸ƒåœ¨å°çº¢ä¹¦ä¸Šçš„é«˜è´¨é‡ç¬”è®°ã€‚

è¯·éµå¾ªä»¥ä¸‹ç»“æ„å’Œè¦æ±‚ï¼š
1. **æ ‡é¢˜**ï¼šåˆ›ä½œä¸€ä¸ªå¸å¼•äººçš„æ ‡é¢˜ï¼ŒåŒ…å« Emojiã€‚
2. **æ ¸å¿ƒæ„è±¡ä¸ç”»é¢æ„Ÿ**ï¼šåˆ†ææ­Œè¯æ„å»ºçš„è§†è§‰åœºæ™¯å’Œç‹¬ç‰¹æ„è±¡ã€‚
3. **ä¿®è¾æ‰‹æ³•ä¸è¯­è¨€ç‚¼å­—**ï¼šåˆ†ææ¯”å–»ã€è±¡å¾ã€é£è¯é€ å¥ã€‚
4. **æƒ…æ„ŸåŸºè°ƒ**ï¼šæè¿°ä¼ è¾¾çš„æƒ…ç»ªã€‚
5. **å“²å­¦/æ–‡åŒ–éšå–»**ï¼šæŒ–æ˜æ·±å±‚å«ä¹‰ã€‚
6. **ä¸€å¥è¯é£æ ¼æ€»ç»“**ï¼šç”¨æå…·æ–‡å­¦æ€§çš„ä¸€å¥è¯æ¦‚æ‹¬è‰ºæœ¯é«˜åº¦ã€‚
7. **æ’ç‰ˆè¦æ±‚**ï¼šä½¿ç”¨ Emoji (âœ¨, ğŸµ, ğŸ“–, ğŸ–‹ï¸ ç­‰) ä¼˜åŒ–æ’ç‰ˆï¼Œä½¿ç”¨åˆ—è¡¨å’ŒåŠ ç²—çªå‡ºé‡ç‚¹ï¼Œæ–‡é£æ–‡è‰ºã€èµ°å¿ƒã€‚
8. **Hashtags**ï¼šåœ¨æ–‡æœ«æ·»åŠ  5-8 ä¸ªç›¸å…³çš„å°çº¢ä¹¦è¯é¢˜æ ‡ç­¾ã€‚

å†™ä½œé£æ ¼çº¦æŸï¼ˆé™ä½ AI æ„Ÿï¼‰ï¼š
- è¯­æ°”è‡ªç„¶å…‹åˆ¶ï¼ŒåƒçœŸå®ä¹è¯„äºº/å°çº¢ä¹¦ç”¨æˆ·ï¼›é¿å…å¤¸é¥°å †å ä¸ç©ºæ³›å¥—è¯ã€‚
- é¿å…â€œæœ¬æ–‡/ä½œä¸º/AI/æ¨¡å‹â€ç­‰å…ƒå™è¿°ã€‚
- å¤šå¼•ç”¨æˆ–è´´è¿‘æ­Œè¯åŸå¥ï¼ˆå¯çŸ­å¼•ï¼‰ï¼Œè§‚ç‚¹è¦è½åœ°ï¼Œä¸è¦æ³›æ³›è€Œè°ˆã€‚
- å¥å¼æœ‰é•¿æœ‰çŸ­ï¼Œå°‘ç”¨æ’æ¯”ï¼›æ§åˆ¶ç¯‡å¹…åœ¨ 300-500 å­—å·¦å³ã€‚
- Emoji é€‚é‡å³å¯ï¼ˆ3-6 ä¸ªï¼‰ï¼Œä¸å¯†é›†åˆ·å±ã€‚

IMPORTANT: At the VERY END of your response, after the hashtags, you MUST output the extracted Song Name and Artist in the following strict format for the system to parse:

===METADATA===
Title: [Song Name]
Artist: [Artist Name]
"""

    user_content = f"""
è¯·åˆ†æä»¥ä¸‹å†…å®¹ï¼ˆå…¶ä¸­åŒ…å«æ­Œåã€æ­Œæ‰‹å’Œæ­Œè¯ï¼‰ï¼š
\"\"\"
{raw_content}
\"\"\"
"""

    try:
        response = client.chat.completions.create(
            model=model or DEFAULT_ANALYSIS_MODEL,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_content}
            ]
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"Error during analysis: {str(e)}"

def parse_analysis_response(full_response):
    parts = full_response.split("===METADATA===")
    xiaohongshu_post = parts[0].strip()
    metadata_part = parts[1].strip() if len(parts) > 1 else ""

    song_name = "Unknown_Song"
    artist = "Unknown_Artist"

    if metadata_part:
        for line in metadata_part.split('\n'):
            if "Title:" in line:
                song_name = line.split("Title:")[1].strip()
            elif "Artist:" in line:
                artist = line.split("Artist:")[1].strip()
    else:
        print("âš ï¸ æœªèƒ½è‡ªåŠ¨æå–å…ƒæ•°æ®ï¼Œå°†ä½¿ç”¨é»˜è®¤æ–‡ä»¶åã€‚")

    return xiaohongshu_post, song_name, artist

def generate_visual_prompt(song_name, artist, analysis_context, model=None):
    """
    Generates 3 Midjourney prompts for minimalist/texture backgrounds (Chinese output).
    """
    print(f"\nğŸ¨ æ­£åœ¨æ„æ€å°é¢èƒŒæ™¯æ–¹æ¡ˆ (Gemini-3-Pro) for {song_name}...")
    client = get_client()

    system_prompt = """ä½ æ˜¯èµ„æ·±å¹³é¢è®¾è®¡å¸ˆï¼Œæ“…é•¿æç®€ä¸»ä¹‰ã€ç‘å£«é£æ ¼ä¸æŠ½è±¡å­—ä½“æµ·æŠ¥ã€‚ç›®æ ‡æ˜¯ç”Ÿæˆå®Œæ•´â€œæ­Œæ›²å¡ç‰‡â€ï¼ˆèƒŒæ™¯+æ’ç‰ˆæ–‡å­—ï¼‰ï¼Œå¯ç›´æ¥ç”¨äºç¤¾åª’å‘å¸ƒã€‚

# ä»»åŠ¡
æ ¹æ®æä¾›çš„ Song Info ç”Ÿæˆ 3 æ¡ Midjourney æ­Œæ›²å¡ç‰‡æç¤ºè¯ï¼Œå¿…é¡»â€œå¹²å‡€ã€ç•™ç™½å……åˆ†ã€é€‚åˆæ‰¿è½½æ–‡å­—â€ï¼Œå¹¶è¦æ±‚å›¾åƒç”Ÿæˆå™¨åœ¨ç”»é¢ä¸­æ¸²æŸ“æ–‡å­—ã€‚
å…ˆåˆ¤æ–­æ­Œæ›²å—ä¼—ï¼ˆå¦‚ï¼šæ–‡è‰º/ç‹¬ç«‹/æ ¡å›­/éƒ½å¸‚/æ²»æ„ˆ/äºŒæ¬¡å…ƒ/å¤å¤ç­‰ï¼‰ï¼Œå†è®©é£æ ¼å’Œæè´¨è´´åˆè¯¥å—ä¼—å®¡ç¾ã€‚
é¿å…æ˜æ˜¾ AI èƒŒæ™¯ï¼šç”»é¢è¦åƒâ€œçœŸå®å°åˆ·æˆ–å®ä½“æè´¨æ‹æ‘„â€çš„æµ·æŠ¥åº•å›¾ã€‚

# è®¾è®¡åŸåˆ™ï¼ˆLess is Moreï¼‰
1. **å‡å°‘ AI ç—•è¿¹**ï¼šé¿å…å¤æ‚æ’ç”»ã€äººè„¸ã€å†™å®åœºæ™¯ã€‚
2. **å¼ºè°ƒè´¨æ„Ÿ**ï¼šä½¿ç”¨ grainy / noise / paper texture / gradient / glass / light leak ç­‰å…³é”®è¯ã€‚
3. **é«˜è®¾è®¡æ„Ÿ**ï¼šåƒé«˜ç«¯ç¾æœ¯é¦†æµ·æŠ¥æˆ–æ¦‚å¿µä¸“è¾‘å°é¢ã€‚
4. **é¢œè‰²**ï¼šå•è‰² / åŒè‰² / ä½é¥±å’Œï¼Œæ‹’ç»æ··ä¹±è‰²å½©ã€‚
5. **ç”»å¹…**ï¼šå›ºå®š --ar 3:4
6. **çœŸå®æ„Ÿçº¦æŸ**ï¼šåŠ å…¥ printmaking / screenprint / letterpress / scanned texture / film grain / lithograph ç­‰å…³é”®è¯ï¼Œé¿å…â€œçº¯æ•°å­—æ¸²æŸ“æ„Ÿâ€ã€‚
7. **æ–‡å­—å¯è¯»æ€§**ï¼šç¡®ä¿æ–‡æœ¬åŒºæœ‰ç¨³å®šçš„æ˜åº¦å¯¹æ¯”ï¼ˆlight background + dark type æˆ– dark background + light typeï¼‰ï¼Œé¿å…çº¹ç†ç©¿è¿‡æ–‡å­—åŒºåŸŸï¼›æŒ‡æ˜â€œtext area is clean, low-noiseâ€ï¼›ä¸‰ç§æ–¹æ¡ˆçš„ä¸»æ–‡å­—å­—å·è¦åå¤§ã€‚

# è¾“å‡ºç»“æ„
[Texture/Material] + [Geometric/Abstract Element] + [Lighting/Mood] + [Color Palette] + [Style Keywords] + [Audience Cue] + [Card Layout Instructions] + [Typography Instructions] + --ar 3:4 --style raw --v 6.0

# è¾“å‡ºé€‰é¡¹ï¼ˆå¿…é¡»ç”Ÿæˆ 3 æ¡ï¼‰
Option Aï¼ˆThe Materialï¼‰ï¼šç”±ä½ è®¾è®¡â€œé«˜çº§æ„Ÿã€è‰ºæœ¯æ€§ã€å®¡ç¾å¼ºâ€çš„æ­Œè¯å¡ç‰‡æ–¹æ¡ˆï¼Œé‡ç‚¹åœ¨æè´¨è§¦æ„Ÿä¸å…‹åˆ¶æ„å›¾ï¼›é¿å…ç”Ÿæˆå¤§é‡èƒŒæ™¯å…ƒç´ ï¼Œç”»é¢åƒå¯ç›´æ¥å‘å¸ƒçš„æˆå“å¡ç‰‡ï¼›é…è‰²æ–¹æ¡ˆå¿…é¡»å…‹åˆ¶ä¸”é«˜çº§ã€‚
Option Bï¼ˆThe Gradientï¼‰ï¼šæŸ”å’ŒæŠ½è±¡æ¸å˜æˆ–å…‰æ™•å½¢æ€ï¼Œçº¯æ°›å›´ï¼›é¿å…å¤æ‚çº¹ç†ä¸å¤šä½™å…ƒç´ ï¼›é…è‰²å…‹åˆ¶é«˜çº§ï¼›ä¸»æ–‡å­—å­—å·åå¤§ã€æ–‡å­—åŒºå¹²å‡€ã€‚
Option Cï¼ˆThe Objectï¼‰ï¼šç©ºæ—·ç”»é¢ä¸­ä¸€ä¸ªæå°ã€é«˜å¯¹æ¯”ç¬¦å·ç‰©ä½“ï¼›å…è®¸ä½ è‡ªç”±å‘æŒ¥å…¶ç¬¦å·ä¸æ„å›¾ï¼ˆä»éœ€ä¿æŒç•™ç™½ä¸é«˜çº§å…‹åˆ¶ï¼‰ï¼›é…è‰²å…‹åˆ¶é«˜çº§ï¼›ä¸»æ–‡å­—å­—å·åå¤§ã€æ–‡å­—åŒºå¹²å‡€ã€‚

# å¤šè¯­è¨€
è¾“å‡ºä¸­æ–‡ã€‚å¦‚æœéœ€è¦æ”¾ç½®æ­Œè¯ï¼Œè¯·ä¿ç•™æ­Œè¯çš„åŸè¯­è¨€ã€‚å…è®¸åŒè¯­å¹¶æ’ã€‚

# æ–‡å­—è§„åˆ™ï¼ˆç”±ä½ å†³å®šå†…å®¹å¤šå°‘ï¼‰
ä½ å¯ä»¥ä»â€œæ­Œå/æ­Œæ‰‹/ä¸€å¥æ­Œè¯/çŸ­å‰¯æ ‡é¢˜/ç‰ˆæƒå£°æ˜â€ä¸­é€‰æ‹©è¦å‡ºç°çš„æ–‡å­—æ•°é‡ä¸ç»„åˆï¼ˆå¯å¤šå¯å°‘ï¼‰ï¼Œå¹¶åœ¨æç¤ºè¯é‡Œå†™å‡ºå…·ä½“æ–‡å­—å†…å®¹ã€‚
è¦æ±‚ï¼šè¯´æ˜å­—ä½“é£æ ¼ã€å­—å·å±‚çº§ã€å¯¹é½æ–¹å¼ã€ç•™ç™½åŒºä½ç½®ï¼›ç¡®ä¿å¯è¯»æ€§ä¸é«˜å¯¹æ¯”ï¼›ä¸»æ ‡é¢˜å­—ä½“åå¤§ï¼ˆå¦‚å ç”»é¢é«˜åº¦çš„ 12-18%ï¼‰ã€‚

# è¾“å‡ºæ ¼å¼
ä»…è¾“å‡º 3 è¡Œæç¤ºè¯ï¼ˆæ¯è¡Œä¸€æ¡ï¼‰ï¼Œä¸è¦è§£é‡Šã€ä¸è¦ Markdownã€ä¸è¦ç¼–å·ã€ä¸è¦å¤šä½™æ–‡å­—ã€‚
"""

    user_content = f"""
Song Name: {song_name}
Artist: {artist}
Vibe: {analysis_context[:500]}... (derived from analysis)
Key Symbol: ä»åˆ†æä¸­æå–æˆ–åˆç†æ¨æ–­ä¸€ä¸ªè±¡å¾ç‰©ï¼ˆå¦‚æœä¸ç¡®å®šï¼Œé€‰æ‹©æŠ½è±¡å‡ ä½•å…ƒç´ ï¼‰ã€‚
"""

    try:
        response = client.chat.completions.create(
            model=model or DEFAULT_PROMPT_MODEL,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_content}
            ]
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"Error during prompt generation: {str(e)}"

def generate_image(prompt, filename, model=None, max_retries=None):
    """
    Generates an image using Nano-Banana-2-4k (Image Mode).
    Saves the image to the specified filename.
    """
    print(f"\nğŸ–¼ï¸ æ­£åœ¨ç”Ÿæˆå°é¢å›¾ç‰‡ (Nano-Banana-Image)...")
    print(f"ğŸ“ ä½¿ç”¨æç¤ºè¯: {prompt[:100]}...")
    client = get_client()

    if max_retries is None:
        max_retries = DEFAULT_IMAGE_MAX_RETRIES

    for attempt in range(1, max_retries + 1):
        try:
            response = client.images.generate(
                model=model or DEFAULT_IMAGE_MODEL,
                prompt=prompt,
                n=1,
                size="1024x1024"
            )

            image_url = response.data[0].url
            print(f"ğŸ”— å›¾ç‰‡ URL: {image_url}")

            # Download and save
            img_data = requests.get(
                image_url,
                timeout=DEFAULT_IMAGE_DOWNLOAD_TIMEOUT
            ).content
            with open(filename, 'wb') as handler:
                handler.write(img_data)

            print(f"âœ… å›¾ç‰‡å·²ä¿å­˜è‡³: {filename}")
            return image_url
        except Exception as e:
            print(f"âŒ å›¾ç‰‡ç”Ÿæˆå¤±è´¥(ç¬¬{attempt}æ¬¡): {str(e)}")
            if attempt < max_retries:
                time.sleep(2 * attempt)
            else:
                return None

def _safe_filename(text):
    safe_name = "".join([c for c in text if c.isalpha() or c.isdigit() or c in (' ', '_')]).rstrip()
    return safe_name if safe_name else "cover_image"

def _split_prompts(raw_prompt):
    lines = [line.strip() for line in raw_prompt.splitlines() if line.strip()]
    return lines if lines else [raw_prompt.strip()]

def run_pipeline(raw_content, output_dir=None, analysis_model=None, prompt_model=None, image_model=None):
    # Step 1: Analysis & Metadata Extraction
    full_response = analyze_lyrics(raw_content, model=analysis_model)
    xiaohongshu_post, song_name, artist = parse_analysis_response(full_response)

    # Step 2: Prompt Generation
    visual_prompt = generate_visual_prompt(song_name, artist, xiaohongshu_post, model=prompt_model)

    # Step 3: Image Generation (3 variants)
    prompts = _split_prompts(visual_prompt)
    safe_name = _safe_filename(song_name)
    if output_dir:
        os.makedirs(output_dir, exist_ok=True)

    images = []
    for idx, prompt in enumerate(prompts[:3], start=1):
        suffix = chr(ord("A") + idx - 1)
        filename = f"{safe_name}_cover_{suffix}.png"
        if output_dir:
            filename = os.path.join(output_dir, filename)
        image_url = generate_image(prompt, filename, model=image_model)
        images.append({
            "prompt": prompt,
            "filename": filename,
            "image_url": image_url
        })

    return {
        "xiaohongshu_post": xiaohongshu_post,
        "song_name": song_name,
        "artist": artist,
        "visual_prompt": visual_prompt,
        "images": images
    }

def main():
    print("=== å°çº¢ä¹¦æ­Œè¯èµææ™ºèƒ½ä½“ (Auto-Mode) ===")
    print("è¯·ç›´æ¥ç²˜è´´åŒ…å«æ­Œåã€æ­Œæ‰‹ã€æ­Œè¯çš„å®Œæ•´å†…å®¹ (è¾“å…¥ 'END' ç»“æŸ):")

    try:
        get_client()
    except RuntimeError as e:
        print(f"Error: {str(e)}")
        return
    
    lines = []
    while True:
        try:
            line = input()
        except EOFError:
            break
        if line.strip().upper() == 'END':
            break
        lines.append(line)
    
    raw_content = "\n".join(lines)
    
    if not raw_content:
        print("æœªè¾“å…¥å†…å®¹ï¼Œç¨‹åºé€€å‡ºã€‚")
        return

    result = run_pipeline(raw_content)

    print("\n" + "="*20 + " [å°çº¢ä¹¦æ–‡æ¡ˆ] " + "="*20)
    print(result["xiaohongshu_post"])
    print("="*50)
    
    print(f"\nğŸ“‹ è¯†åˆ«ä¿¡æ¯: æ­Œå [{result['song_name']}], æ­Œæ‰‹ [{result['artist']}]")
    print(f"\nğŸ¨ ç”Ÿæˆçš„ç”Ÿå›¾æç¤ºè¯: {result['visual_prompt']}")

    print("\nâœ¨ ä»»åŠ¡å…¨éƒ¨å®Œæˆï¼è¯·æŸ¥çœ‹ç”Ÿæˆçš„å°çº¢ä¹¦æ–‡æ¡ˆä¸å°é¢å›¾ã€‚")

if __name__ == "__main__":
    main()
